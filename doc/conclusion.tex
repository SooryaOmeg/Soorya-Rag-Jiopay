\section{Conclusion}

In this study, we conducted a comprehensive evaluation of chunking, embedding, and retrieval-augmented generation (RAG) strategies for knowledge-intensive question answering. Structural Balanced and Structural Hierarchical chunking strategies were selected based on their strong trade-off between retrieval performance and index efficiency. Multiple embedding models, including Qwen3-0.6B, Gemma-300M, and Voyage-3.5, were benchmarked, highlighting the balance between accuracy, latency, and memory footprint.

The RAG evaluation demonstrated that combining high-quality embeddings with top-k retrieval, rerankers, and guardrails produces reliable and semantically relevant answers, with Voyage-3.5 achieving the highest quality metrics albeit at higher latency. Our framework provides a systematic methodology for evaluating retrieval and generation performance across multiple models, offering insights into model selection and deployment trade-offs.

Overall, the study emphasizes the importance of careful chunking, embedding selection, and retrieval strategy design to achieve a robust and efficient knowledge retrieval system. The results serve as a foundation for further optimization, including latency reduction, domain-specific fine-tuning, and adaptive retrieval strategies.